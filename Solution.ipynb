{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73586fe2-5b57-4958-9227-4dd7c0422448",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, DateType, StringType, IntegerType, FloatType,TimestampType\n",
    "from pyspark.sql.functions import col, to_timestamp\\\n",
    "    \n",
    "\n",
    "# Define the schema of your CSV file\n",
    "schema = StructType([\n",
    "    StructField(\"Order ID\", IntegerType(), False),\n",
    "    StructField(\"Product\", StringType(), False),  \n",
    "    StructField(\"Quantity Ordered\", IntegerType(), False),\n",
    "    StructField(\"Price Each\", FloatType(), False),\n",
    "    StructField(\"Order Date\", TimestampType(), False),\n",
    "    StructField(\"Purchase Address\", StringType(), True)\n",
    "])\n",
    "\n",
    "new_schema = StructType([\n",
    "    StructField(\"Order_id\", StringType()),\n",
    "    StructField(\"Product\", StringType()),  \n",
    "    StructField(\"Quantity\", StringType()),\n",
    "    StructField(\"Price\", StringType()),\n",
    "    StructField(\"Order_date\", StringType()),\n",
    "    StructField(\"Address\", StringType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d88c864f-a74e-4b47-944a-b88fad7c489e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Order ID: string (nullable = true)\n |-- Product: string (nullable = true)\n |-- Quantity Ordered: string (nullable = true)\n |-- Price Each: string (nullable = true)\n |-- Order Date: string (nullable = true)\n |-- Purchase Address: string (nullable = true)\n\nroot\n |-- Order_id: string (nullable = true)\n |-- Product: string (nullable = true)\n |-- Quantity: string (nullable = true)\n |-- Price: string (nullable = true)\n |-- Order_date: string (nullable = true)\n |-- Address: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", False) \\\n",
    "  .option(\"header\", True) \\\n",
    "  .option(\"sep\", ',') \\\n",
    "  .load([\"dbfs:/FileStore/Sales_January_2019.csv\",\"dbfs:/FileStore/Sales_February_2019.csv\",\"dbfs:/FileStore/Sales_March_2019.csv\"])\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# Create a Dataframe with new schema with Renamed Column names and schema.\n",
    "\n",
    "df2 = spark.createDataFrame(df.rdd, schema=new_schema)\n",
    "\n",
    "df2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "587867f6-b108-4142-b2ee-bd7922a4c70d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+--------+------+-------------------+---------------------------------------+------+\n|Order_id|Product                   |Quantity|Price |Order_date         |Address                                |sales |\n+--------+--------------------------+--------+------+-------------------+---------------------------------------+------+\n|174575  |AA Batteries (4-pack)     |1       |3.84  |2019-04-01 03:21:00|969 Adams St, Boston, MA 02215         |3.84  |\n|165622  |Lightning Charging Cable  |1       |14.95 |2019-04-01 02:59:00|65 Madison St, Boston, MA 02215        |14.95 |\n|167813  |27in 4K Gaming Monitor    |1       |389.99|2019-04-01 02:42:00|840 11th St, Seattle, WA 98101         |389.99|\n|175769  |Bose SoundSport Headphones|1       |99.99 |2019-04-01 02:22:00|974 13th St, New York City, NY 10001   |99.99 |\n|166309  |AA Batteries (4-pack)     |1       |3.84  |2019-04-01 01:32:00|2 Church St, Seattle, WA 98101         |3.84  |\n|169177  |Macbook Pro Laptop        |1       |1700  |2019-04-01 01:20:00|220 1st St, New York City, NY 10001    |1700.0|\n|167231  |AAA Batteries (4-pack)    |1       |2.99  |2019-04-01 01:19:00|689 Hill St, San Francisco, CA 94016   |2.99  |\n|162541  |AAA Batteries (4-pack)    |2       |2.99  |2019-04-01 01:15:00|672 2nd St, Atlanta, GA 30301          |5.98  |\n|162358  |Flatscreen TV             |1       |300   |2019-04-01 01:11:00|444 12th St, New York City, NY 10001   |300.0 |\n|168905  |USB-C Charging Cable      |1       |11.95 |2019-04-01 01:00:00|241 Spruce St, Boston, MA 02215        |11.95 |\n|168905  |ThinkPad Laptop           |1       |999.99|2019-04-01 01:00:00|241 Spruce St, Boston, MA 02215        |999.99|\n|174959  |Bose SoundSport Headphones|1       |99.99 |2019-04-01 00:52:00|288 Lincoln St, New York City, NY 10001|99.99 |\n|169191  |27in FHD Monitor          |1       |149.99|2019-04-01 00:42:00|310 Cherry St, Los Angeles, CA 90001   |149.99|\n|165007  |34in Ultrawide Monitor    |1       |379.99|2019-04-01 00:12:00|389 Willow St, New York City, NY 10001 |379.99|\n|166567  |34in Ultrawide Monitor    |1       |379.99|2019-04-01 00:12:00|937 Cedar St, New York City, NY 10001  |379.99|\n|166250  |Lightning Charging Cable  |1       |14.95 |2019-04-01 00:11:00|159 Walnut St, Los Angeles, CA 90001   |14.95 |\n|175951  |LG Dryer                  |1       |600.0 |2019-04-01 00:04:00|469 Walnut St, Dallas, TX 75001        |600.0 |\n|168990  |Wired Headphones          |1       |11.99 |2019-04-01 00:00:00|790 10th St, Boston, MA 02215          |11.99 |\n|174571  |AAA Batteries (4-pack)    |1       |2.99  |2019-03-31 23:46:00|58 River St, Seattle, WA 98101         |2.99  |\n|165922  |Bose SoundSport Headphones|1       |99.99 |2019-03-31 23:38:00|948 Willow St, San Francisco, CA 94016 |99.99 |\n+--------+--------------------------+--------+------+-------------------+---------------------------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Handling Inconsistent Data \n",
    "\n",
    "df3 = df2.withColumn(\"Order_date\",to_timestamp(col(\"Order_date\"), \"MM/dd/yy HH:mm\").alias(\"Order_date\"))\n",
    "\n",
    "# Create a temporary view for the DataFrame to use Spark SQL\n",
    "df3.createOrReplaceTempView(\"Orders\")\n",
    "\n",
    "\n",
    "# Fixing the Outliers and Missing values(Blank Rows) with new temp view 'Orders2'\n",
    "\n",
    "df4 = spark.sql(sqlQuery=\"SELECT *,(Quantity*Price) as sales FROM Orders WHERE Order_id IS NOT NULL AND Order_id <> 'Order ID' ORDER BY Order_date DESC\").createOrReplaceTempView(\"Orders2\")\n",
    "\n",
    "\n",
    "# Convert Nonetype to dataframe\n",
    "df5=spark.sql(\"select * from Orders2\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "884e3189-8454-4d15-a9fd-048896b510a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+\n|Product           |Order_date         |sales |\n+------------------+-------------------+------+\n|Macbook Pro Laptop|2019-03-31 10:12:00|3400.0|\n+------------------+-------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#2.\tGet the date on which max sales was done by a product in these 3 months\n",
    "max_sales_date_one_product_df=spark.sql(sqlQuery=\"select Product,Order_date,SUM(Quantity*Price) AS sales FROM Orders2 group by Order_date,Product order by sales desc,Order_date desc limit 1\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1232b957-4834-4e0c-8343-38be5b29d7e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+-------+\n|Product           |Order_date         |sales  |\n+------------------+-------------------+-------+\n|Macbook Pro Laptop|2019-03-31 10:12:00|3400.0 |\n|Macbook Pro Laptop|2019-03-30 10:47:00|3400.0 |\n|Macbook Pro Laptop|2019-03-29 21:17:00|3400.0 |\n|Macbook Pro Laptop|2019-03-05 21:25:00|3400.0 |\n|Macbook Pro Laptop|2019-02-26 17:12:00|3400.0 |\n|Macbook Pro Laptop|2019-02-22 21:06:00|3400.0 |\n|Macbook Pro Laptop|2019-01-20 00:15:00|3400.0 |\n|ThinkPad Laptop   |2019-03-31 22:20:00|1999.98|\n|ThinkPad Laptop   |2019-03-25 18:39:00|1999.98|\n|ThinkPad Laptop   |2019-03-22 11:55:00|1999.98|\n|ThinkPad Laptop   |2019-03-16 13:17:00|1999.98|\n|ThinkPad Laptop   |2019-03-11 09:38:00|1999.98|\n|ThinkPad Laptop   |2019-02-21 17:24:00|1999.98|\n|ThinkPad Laptop   |2019-01-31 17:47:00|1999.98|\n|Macbook Pro Laptop|2019-04-01 01:20:00|1700.0 |\n|Macbook Pro Laptop|2019-03-31 22:25:00|1700.0 |\n|Macbook Pro Laptop|2019-03-31 19:19:00|1700.0 |\n|Macbook Pro Laptop|2019-03-31 17:38:00|1700.0 |\n|Macbook Pro Laptop|2019-03-31 17:03:00|1700.0 |\n|Macbook Pro Laptop|2019-03-31 15:44:00|1700.0 |\n+------------------+-------------------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#3.\tGet the date on which max sales was done for all products in these 3 months\n",
    "max_sales_date_all_product_df=spark.sql(sqlQuery=\"select Product,Order_date,SUM(Quantity*Price) AS sales FROM Orders2 group by Order_date,Product order by sales desc,Order_date desc\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8482f4-6434-499f-9a0c-8e59ae058d63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------------+\n|Product                   |sales             |\n+--------------------------+------------------+\n|Macbook Pro Laptop        |1700.0            |\n|ThinkPad Laptop           |1001.1847311827881|\n|iPhone                    |700.5166051660517 |\n|Google Phone              |601.5530629853322 |\n|LG Dryer                  |600.0             |\n|LG Washing Machine        |600.0             |\n|Vareebadd Phone           |400.9367681498829 |\n|27in 4K Gaming Monitor    |390.95214638157285|\n|34in Ultrawide Monitor    |381.20402555909936|\n|Flatscreen TV             |301.3114754098361 |\n|Apple Airpods Headphones  |150.76628352490422|\n|27in FHD Monitor          |150.69182486630766|\n|20in Monitor              |110.69326086956595|\n|Bose SoundSport Headphones|100.9999999999964 |\n|Lightning Charging Cable  |16.03862666034043 |\n|USB-C Charging Cable      |13.095375982041809|\n|Wired Headphones          |13.036129119394804|\n|AA Batteries (4-pack)     |5.174857142857302 |\n|AAA Batteries (4-pack)    |4.464702542581974 |\n+--------------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#4.\tGet the average sales value for each product in these 3 months\n",
    "Avg_sales_per_product_df=spark.sql(sqlQuery=\"select Product,AVG(Quantity*Price) AS sales FROM Orders2 group by Product order by Sales desc\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47f2f8db-742e-42ff-8053-347a77b271d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------+------+-------------------+-----------------------------------------+------+---------+\n|Order_id|Product     |Quantity|Price |Order_date         |Address                                  |sales |salesdiff|\n+--------+------------+--------+------+-------------------+-----------------------------------------+------+---------+\n|169023  |20in Monitor|1       |109.99|2019-03-31 22:02:00|404 Chestnut St, San Francisco, CA 94016 |109.99|0.0      |\n|169504  |20in Monitor|1       |109.99|2019-03-31 19:38:00|338 Meadow St, Los Angeles, CA 90001     |109.99|0.0      |\n|174561  |20in Monitor|1       |109.99|2019-03-31 19:38:00|337 River St, Portland, OR 97035         |109.99|0.0      |\n|172744  |20in Monitor|1       |109.99|2019-03-31 16:37:00|476 Jefferson St, San Francisco, CA 94016|109.99|0.0      |\n|171872  |20in Monitor|1       |109.99|2019-03-31 13:57:00|466 Pine St, San Francisco, CA 94016     |109.99|0.0      |\n|168204  |20in Monitor|1       |109.99|2019-03-31 13:20:00|813 10th St, Los Angeles, CA 90001       |109.99|0.0      |\n|173846  |20in Monitor|1       |109.99|2019-03-31 10:52:00|190 Willow St, Dallas, TX 75001          |109.99|0.0      |\n|163693  |20in Monitor|1       |109.99|2019-03-31 08:15:00|523 2nd St, Los Angeles, CA 90001        |109.99|0.0      |\n|169548  |20in Monitor|1       |109.99|2019-03-31 05:39:00|345 Main St, Austin, TX 73301            |109.99|0.0      |\n|168568  |20in Monitor|1       |109.99|2019-03-31 02:01:00|262 Elm St, Austin, TX 73301             |109.99|0.0      |\n|176251  |20in Monitor|1       |109.99|2019-03-31 00:29:00|965 Church St, New York City, NY 10001   |109.99|0.0      |\n|168197  |20in Monitor|1       |109.99|2019-03-30 21:43:00|107 1st St, San Francisco, CA 94016      |109.99|0.0      |\n|173362  |20in Monitor|1       |109.99|2019-03-30 18:28:00|767 River St, San Francisco, CA 94016    |109.99|0.0      |\n|162811  |20in Monitor|1       |109.99|2019-03-30 15:30:00|147 Adams St, Boston, MA 02215           |109.99|0.0      |\n|167194  |20in Monitor|1       |109.99|2019-03-30 14:21:00|491 Lincoln St, San Francisco, CA 94016  |109.99|0.0      |\n|162603  |20in Monitor|1       |109.99|2019-03-30 13:34:00|794 North St, Austin, TX 73301           |109.99|0.0      |\n|174005  |20in Monitor|1       |109.99|2019-03-30 12:55:00|899 8th St, Los Angeles, CA 90001        |109.99|0.0      |\n|164522  |20in Monitor|1       |109.99|2019-03-29 23:20:00|201 Lincoln St, Los Angeles, CA 90001    |109.99|0.0      |\n|163452  |20in Monitor|1       |109.99|2019-03-29 22:55:00|436 Ridge St, Los Angeles, CA 90001      |109.99|0.0      |\n|171609  |20in Monitor|1       |109.99|2019-03-29 22:09:00|52 Park St, Los Angeles, CA 90001        |109.99|0.0      |\n+--------+------------+--------+------+-------------------+-----------------------------------------+------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#5.add a new column which is “salesdiff” where this column will contain the difference of the sales in the current row (current date of that row) and the next row (previous date of that row, as the date columns are sorted by desc) grouped on the product\n",
    "\n",
    "\n",
    "\n",
    "salesdiff_df=spark.sql(\"SELECT *,sales - LEAD(sales, 1) OVER (PARTITION BY Product ORDER BY Order_date DESC) AS salesdiff FROM Orders2\").createOrReplaceTempView(\"Salesdiff\")\n",
    "\n",
    "\n",
    "# Convert Nonetype to dataframe\n",
    "Final_salesdiff_df=spark.sql(\"select * from Salesdiff\").show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c624527e-f40e-4b5f-8547-38e3abecc111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------+------+\n|Order_id|Address                             |sales |\n+--------+------------------------------------+------+\n|150518  |847 10th St, San Francisco, CA 94016|2400.0|\n+--------+------------------------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#6.\tGet the orderId and purchase address details who made max sales in all the 3 months\n",
    "\n",
    "max_sales_order_id_address_df=spark.sql(sqlQuery=\"select Order_id,Address,SUM(Quantity*Price) as sales from  Orders2 group by Order_id,Address order by sales desc limit 1\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13bc58e4-ec8f-43ca-a39a-1e3564f59bc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n|          city|No_of_orders|\n+--------------+------------+\n| San Francisco|        8863|\n+--------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#7.\tExtract city from the purchase address column which is 2nd element in , delimited separated string and determine the city from where more orders came in all these 3 months\n",
    "from pyspark.sql.functions import split, col, count, desc\n",
    "\n",
    "df_city2=spark.sql(\"SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(Address, ',', 2), ',', -1) AS City FROM Orders2\").createOrReplaceTempView(\"OrdersWithCity\")\n",
    "\n",
    "\n",
    "address_city_df=spark.sql(\"select * from OrdersWithCity\")\n",
    "\n",
    "#address_city_df.show()\n",
    "\n",
    "Max_orders_from_city_df=spark.sql(\"select city,count(*) as No_of_orders from OrdersWithCity group by city order by No_of_orders desc limit 1 \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e5c0400-cb41-4dad-a734-6d08cd908ffd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n|          city|No_of_orders|\n+--------------+------------+\n| San Francisco|        8863|\n|   Los Angeles|        5886|\n| New York City|        4895|\n|        Boston|        3952|\n|        Dallas|        2968|\n|       Atlanta|        2967|\n|       Seattle|        2855|\n|      Portland|        2442|\n|        Austin|        1993|\n+--------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#8.\tGet the total order count details for each city in all the 3 months\n",
    "\n",
    "Total_orders_from_cities_df=spark.sql(\"select city,count(*) as No_of_orders from OrdersWithCity where city IS NOT NULL group by city order by No_of_orders desc\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Solution",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
